{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ‚òï Mini Project: Coffee Shop Analytics Challenge\n",
    "\n",
    "## Welcome, Data Analyst!\n",
    "\n",
    "You've just been hired by **\"Brewed Awakening\"**, a popular coffee shop in your city. The owner wants to:\n",
    "\n",
    "1. üìà **Predict** next week's coffee sales\n",
    "2. üîç **Discover** recurring customer traffic patterns\n",
    "3. üí° **Recommend** optimal staffing times\n",
    "\n",
    "Your task is to analyze historical data and provide actionable insights!\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Project Objectives\n",
    "\n",
    "By the end of this project, you will:\n",
    "- Clean messy sales data\n",
    "- Apply preprocessing techniques\n",
    "- Build a forecasting model\n",
    "- Detect traffic patterns\n",
    "- Present findings to the coffee shop owner\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Instructions\n",
    "\n",
    "This is a **guided project**. Follow each step and copy/modify code from your lesson notebooks:\n",
    "- üìì **Lesson 1**: For data preprocessing (cleaning, smoothing, etc.)\n",
    "- üìì **Lesson 2**: For forecasting and pattern detection\n",
    "\n",
    "**Let's begin!** ‚òï‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Setup\n",
    "\n",
    "**üìù TODO:** Copy the import statements from **Lesson 1, cell 2** to import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy import statements from Lesson 1 here\n",
    "# You'll need: numpy, pandas, matplotlib, seaborn, scipy\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Also copy imports from Lesson 2 for ARIMA\n",
    "# You'll need: ARIMA and related functions\n",
    "\n",
    "\n",
    "\n",
    "# Run this cell to verify imports work\n",
    "print(\"‚úÖ All libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Load the Data\n",
    "\n",
    "The coffee shop has been tracking hourly coffee sales for the past 60 days. Let's load this data!\n",
    "\n",
    "**Run the cell below** to generate the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate coffee shop sales data (DO NOT MODIFY - just run this cell)\n",
    "np.random.seed(123)\n",
    "\n",
    "# 60 days of hourly data\n",
    "hours = pd.date_range('2024-01-01', periods=24*60, freq='h')\n",
    "n = len(hours)\n",
    "\n",
    "# Base pattern: more sales during day, peaks at morning and afternoon\n",
    "hour_of_day = np.array([h.hour for h in hours])\n",
    "day_of_week = np.array([h.dayofweek for h in hours])  # 0=Monday, 6=Sunday\n",
    "\n",
    "# Morning rush (7-9am) and afternoon rush (2-4pm)\n",
    "morning_rush = 30 * np.exp(-((hour_of_day - 8)**2) / 4)\n",
    "afternoon_rush = 25 * np.exp(-((hour_of_day - 15)**2) / 4)\n",
    "\n",
    "# Weekend boost (10% more sales on Sat/Sun)\n",
    "weekend_boost = np.where((day_of_week == 5) | (day_of_week == 6), 10, 0)\n",
    "\n",
    "# Overall trend (business growing)\n",
    "trend = 0.02 * np.arange(n)\n",
    "\n",
    "# Base sales + components\n",
    "base = 20\n",
    "clean_sales = base + trend + morning_rush + afternoon_rush + weekend_boost\n",
    "\n",
    "# Add PROBLEMS to make it realistic!\n",
    "dirty_sales = clean_sales.copy()\n",
    "\n",
    "# Problem 1: Add noise\n",
    "dirty_sales += np.random.normal(0, 5, n)\n",
    "\n",
    "# Problem 2: Missing values (15% - register malfunctions!)\n",
    "missing_idx = np.random.choice(n, size=int(n * 0.15), replace=False)\n",
    "dirty_sales[missing_idx] = np.nan\n",
    "\n",
    "# Problem 3: Outliers (8% - data entry errors!)\n",
    "outlier_idx = np.random.choice(n, size=int(n * 0.08), replace=False)\n",
    "dirty_sales[outlier_idx] += np.random.choice([-1, 1], size=len(outlier_idx)) * np.random.uniform(40, 80, size=len(outlier_idx))\n",
    "\n",
    "# Problem 4: Some negative values (data errors - can't have negative sales!)\n",
    "dirty_sales = np.maximum(dirty_sales, 0)\n",
    "\n",
    "# Create DataFrame\n",
    "df_coffee = pd.DataFrame({\n",
    "    'timestamp': hours,\n",
    "    'sales': dirty_sales,\n",
    "    'hour': hour_of_day,\n",
    "    'day_of_week': day_of_week\n",
    "})\n",
    "\n",
    "print(\"‚òï Coffee Shop Sales Data Loaded!\")\n",
    "print(f\"üìä Dataset: {len(df_coffee)} hours ({len(df_coffee)/24:.0f} days)\")\n",
    "print(f\"üìÖ Period: {df_coffee['timestamp'].min()} to {df_coffee['timestamp'].max()}\")\n",
    "print(f\"\\n‚ö†Ô∏è  Data Quality Issues Detected:\")\n",
    "print(f\"   - Missing values: {df_coffee['sales'].isna().sum()} ({df_coffee['sales'].isna().sum()/len(df_coffee)*100:.1f}%)\")\n",
    "print(f\"   - Suspicious outliers: ~{int(n * 0.08)} points\")\n",
    "print(f\"\\nüéØ Your mission: Clean this data and make predictions!\")\n",
    "\n",
    "# Show first few rows\n",
    "df_coffee.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Visualize the Raw Data\n",
    "\n",
    "Before cleaning, let's see what we're working with!\n",
    "\n",
    "**üìù TODO:** Copy the visualization code from **Lesson 1, cell 23** and modify it to plot the coffee sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a plot showing the coffee sales over time\n",
    "# Hint: Copy from Lesson 1, cell 23 and adapt for df_coffee\n",
    "\n",
    "\n",
    "\n",
    "# Your observations:\n",
    "print(\"\\nü§î What do you notice?\")\n",
    "print(\"1. Are there any obvious patterns? _________________\")\n",
    "print(\"2. Do you see outliers? _________________\")\n",
    "print(\"3. Are there gaps (missing data)? _________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Handle Missing Data\n",
    "\n",
    "The cash register sometimes malfunctions! We need to fill in missing sales data.\n",
    "\n",
    "**üìù TODO:** \n",
    "1. Copy the missing data handling code from **Lesson 1, cell 25 and 27**\n",
    "2. Decide which method is best for coffee shop sales\n",
    "3. Apply it to `df_coffee['sales']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy missing data handling code from Lesson 1, cell 25\n",
    "# Try different methods: forward fill, backward fill, interpolation\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Choose the best method and apply it\n",
    "# Create a new column 'sales_clean' with filled values\n",
    "df_coffee['sales_clean'] = df_coffee['sales']  # Replace this line with your solution\n",
    "\n",
    "\n",
    "\n",
    "# Verify missing values are handled\n",
    "print(f\"‚úÖ Missing values remaining: {df_coffee['sales_clean'].isna().sum()}\")\n",
    "\n",
    "# Why did you choose this method?\n",
    "print(\"\\nüí≠ I chose __________ because: __________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Detect and Handle Outliers\n",
    "\n",
    "Some data points are suspiciously high (data entry errors). Let's find and fix them!\n",
    "\n",
    "**üìù TODO:**\n",
    "1. Copy the outlier detection code from **Lesson 1, cell 37**\n",
    "2. Copy the outlier handling code from **Lesson 1, cell 39**\n",
    "3. Apply the IQR method to detect outliers in coffee sales\n",
    "4. Choose a strategy to handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy outlier detection code from Lesson 1, cell 37\n",
    "# Use the IQR method on df_coffee['sales_clean']\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Visualize the outliers\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Handle outliers using one of the strategies from cell 39\n",
    "# Options: remove (set to NaN), cap at bounds, or replace with median\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nüìä Outliers detected: {outliers_iqr.sum()}\")\n",
    "print(f\"üí≠ I chose to handle them by: __________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Smooth the Data\n",
    "\n",
    "Sales data is noisy! Let's smooth it to see patterns more clearly.\n",
    "\n",
    "**üìù TODO:**\n",
    "1. Copy the smoothing functions from **Lesson 1, cell 29**\n",
    "2. Experiment with different window sizes\n",
    "3. Apply smoothing to create `df_coffee['sales_smoothed']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy the moving_average and exponential_smoothing functions from Lesson 1, cell 29\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Experiment with different parameters (copy from cell 31)\n",
    "window_size = 6  # Try different values: 3, 6, 12, 24\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Apply your chosen smoothing method\n",
    "df_coffee['sales_smoothed'] = df_coffee['sales_clean']  # Replace with smoothed version\n",
    "\n",
    "\n",
    "\n",
    "# Visualize before and after\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_coffee['timestamp'], df_coffee['sales'], alpha=0.3, label='Raw (with problems)', linewidth=0.5)\n",
    "plt.plot(df_coffee['timestamp'], df_coffee['sales_smoothed'], linewidth=2, label='Cleaned & Smoothed', color='green')\n",
    "plt.title('‚òï Coffee Sales: Before vs After Preprocessing', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Coffee Sales (cups)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Data preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Test for Stationarity\n",
    "\n",
    "Before forecasting, we need to check if our data is stationary!\n",
    "\n",
    "**üìù TODO:** Copy the ADF test function from **Lesson 2, cell 19** and test the smoothed sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy the adf_test function from Lesson 2, cell 19\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Test the smoothed sales data\n",
    "# Fill any remaining NaN values first\n",
    "df_coffee['sales_smoothed'] = df_coffee['sales_smoothed'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "\n",
    "\n",
    "# Is the data stationary?\n",
    "print(\"\\nüí≠ The data is: ‚òê Stationary  ‚òê Non-stationary\")\n",
    "print(\"   This means we need d = ___ for our ARIMA model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Determine ARIMA Parameters\n",
    "\n",
    "Use ACF and PACF plots to choose (p, d, q) parameters!\n",
    "\n",
    "**üìù TODO:** Copy the ACF/PACF plotting code from **Lesson 2, cell 21**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy ACF/PACF plotting code from Lesson 2, cell 21\n",
    "# Adjust for df_coffee['sales_smoothed']\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Based on the plots, choose your ARIMA parameters\n",
    "print(\"\\nüéØ Based on the ACF/PACF plots:\")\n",
    "print(\"   p (from PACF cutoff) = ___\")\n",
    "print(\"   d (from stationarity test) = ___\")\n",
    "print(\"   q (from ACF cutoff) = ___\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9: Fit ARIMA Model and Forecast\n",
    "\n",
    "Now the exciting part - predicting next week's sales!\n",
    "\n",
    "**üìù TODO:** Copy the ARIMA fitting and forecasting code from **Lesson 2, cells 23 and 25**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy ARIMA model fitting code from Lesson 2, cell 23\n",
    "# Set your chosen (p, d, q) parameters\n",
    "p = 1  # Change based on your analysis\n",
    "d = 1  # Change based on your analysis\n",
    "q = 1  # Change based on your analysis\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Make a 7-day (168 hour) forecast using code from cell 25\n",
    "forecast_hours = 24 * 7  # One week\n",
    "\n",
    "\n",
    "\n",
    "# Visualize the forecast\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n‚úÖ Forecast complete! Your ARIMA({p},{d},{q}) model predicts:\")\n",
    "print(f\"   Average daily sales next week: _____ cups\")\n",
    "print(f\"   Peak hour sales: _____ cups\")\n",
    "print(f\"   Model confidence: Check the confidence interval width!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 10: Find Traffic Patterns (Motifs)\n",
    "\n",
    "Let's discover when the coffee shop is busiest!\n",
    "\n",
    "**üìù TODO:** \n",
    "1. Aggregate hourly sales by hour of day (0-23)\n",
    "2. Visualize the average sales per hour\n",
    "3. Identify peak times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate average sales for each hour of the day\n",
    "# Hint: Use groupby on the 'hour' column\n",
    "\n",
    "hourly_avg = df_coffee.groupby('hour')['sales_smoothed'].mean()\n",
    "\n",
    "# Visualize hourly patterns\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(hourly_avg.index, hourly_avg.values, color='brown', alpha=0.7, edgecolor='black')\n",
    "plt.axhline(y=hourly_avg.mean(), color='red', linestyle='--', linewidth=2, label=f'Average: {hourly_avg.mean():.1f} cups/hour')\n",
    "plt.title('‚òï Average Coffee Sales by Hour of Day', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Hour of Day (0 = Midnight, 12 = Noon)')\n",
    "plt.ylabel('Average Sales (cups)')\n",
    "plt.xticks(range(0, 24))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find peak hours\n",
    "peak_hours = hourly_avg.nlargest(3)\n",
    "print(\"\\nüî• Top 3 Busiest Hours:\")\n",
    "for hour, sales in peak_hours.items():\n",
    "    print(f\"   {hour}:00 - {hour+1}:00 ‚Üí {sales:.1f} cups (avg)\")\n",
    "\n",
    "# Find slowest hours\n",
    "slow_hours = hourly_avg.nsmallest(3)\n",
    "print(\"\\nüò¥ Top 3 Slowest Hours:\")\n",
    "for hour, sales in slow_hours.items():\n",
    "    print(f\"   {hour}:00 - {hour+1}:00 ‚Üí {sales:.1f} cups (avg)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "**üìù TODO:** Now analyze weekend vs weekday patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare weekday vs weekend sales\n",
    "# Hint: Create a new column 'is_weekend' based on day_of_week\n",
    "\n",
    "df_coffee['is_weekend'] = df_coffee['day_of_week'].isin([5, 6])\n",
    "\n",
    "# Calculate averages\n",
    "weekday_avg = df_coffee[~df_coffee['is_weekend']]['sales_smoothed'].mean()\n",
    "weekend_avg = df_coffee[df_coffee['is_weekend']]['sales_smoothed'].mean()\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "categories = ['Weekday', 'Weekend']\n",
    "values = [weekday_avg, weekend_avg]\n",
    "colors = ['skyblue', 'coral']\n",
    "plt.bar(categories, values, color=colors, edgecolor='black', linewidth=2)\n",
    "plt.title('‚òï Weekday vs Weekend Sales', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Average Sales per Hour (cups)')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 1, f'{v:.1f}', ha='center', fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Analysis:\")\n",
    "print(f\"   Weekday average: {weekday_avg:.1f} cups/hour\")\n",
    "print(f\"   Weekend average: {weekend_avg:.1f} cups/hour\")\n",
    "print(f\"   Difference: {abs(weekend_avg - weekday_avg):.1f} cups/hour ({abs(weekend_avg - weekday_avg)/weekday_avg*100:.1f}%)\")\n",
    "\n",
    "if weekend_avg > weekday_avg:\n",
    "    print(f\"\\nüí° Insight: Weekends are busier! Consider extra staff.\")\n",
    "else:\n",
    "    print(f\"\\nüí° Insight: Weekdays are busier! Likely due to morning commuters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 11: Business Recommendations\n",
    "\n",
    "Time to turn your analysis into actionable insights for the coffee shop owner!\n",
    "\n",
    "**üìù TODO:** Fill in your recommendations based on your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### üìã Your Report to \"Brewed Awakening\" Owner\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. üìà Sales Forecast (Next 7 Days)\n",
    "\n",
    "**Model Used:** ARIMA(__, __, __)\n",
    "\n",
    "**Key Predictions:**\n",
    "- Expected daily average: _____ cups\n",
    "- Peak day: _______________\n",
    "- Slowest day: _____________\n",
    "- Confidence level: _________\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. üîç Traffic Patterns Discovered\n",
    "\n",
    "**Busiest Hours:** (When do we need most staff?)\n",
    "1. ___:00 - ___:00\n",
    "2. ___:00 - ___:00\n",
    "3. ___:00 - ___:00\n",
    "\n",
    "**Slowest Hours:** (When can we reduce staff?)\n",
    "1. ___:00 - ___:00\n",
    "2. ___:00 - ___:00\n",
    "3. ___:00 - ___:00\n",
    "\n",
    "**Weekend vs Weekday:**\n",
    "- Weekend sales are ___% (higher/lower) than weekdays\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. üí° Top 3 Recommendations\n",
    "\n",
    "**Recommendation 1: Staffing**\n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "**Recommendation 2: Inventory**\n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "**Recommendation 3: Promotions**\n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. üéì What I Learned\n",
    "\n",
    "**Most challenging part of this project:**\n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "**Most interesting insight:**\n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "**How could this analysis be improved?**\n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ Bonus Challenge (Optional)\n",
    "\n",
    "Want to go further? Try these extensions:\n",
    "\n",
    "### Challenge 1: Model Comparison\n",
    "Try 3 different ARIMA parameter combinations and compare their MAE/RMSE. Which performs best?\n",
    "\n",
    "### Challenge 2: Seasonal Patterns\n",
    "Try to detect repeating daily patterns using the motif detection code from Lesson 2, cell 39. Can you find the \"morning rush\" pattern?\n",
    "\n",
    "### Challenge 3: What-If Analysis\n",
    "What if sales increase by 20% next month due to a marketing campaign? How would that affect staffing needs?\n",
    "\n",
    "### Challenge 4: Create a Dashboard\n",
    "Make an executive summary with 3-4 key visualizations that tell the complete story!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your bonus challenge code here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Project Checklist\n",
    "\n",
    "Before submitting, make sure you completed:\n",
    "\n",
    "- [ ] ‚úÖ Imported all necessary libraries\n",
    "- [ ] ‚úÖ Visualized raw data\n",
    "- [ ] ‚úÖ Handled missing values\n",
    "- [ ] ‚úÖ Detected and handled outliers\n",
    "- [ ] ‚úÖ Smoothed the data\n",
    "- [ ] ‚úÖ Tested for stationarity\n",
    "- [ ] ‚úÖ Analyzed ACF/PACF plots\n",
    "- [ ] ‚úÖ Chose ARIMA parameters\n",
    "- [ ] ‚úÖ Fit ARIMA model\n",
    "- [ ] ‚úÖ Made 7-day forecast\n",
    "- [ ] ‚úÖ Found traffic patterns\n",
    "- [ ] ‚úÖ Analyzed weekday vs weekend\n",
    "- [ ] ‚úÖ Completed recommendations report\n",
    "- [ ] ‚úÖ Reflected on what I learned\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Congratulations!\n",
    "\n",
    "You've successfully completed the Coffee Shop Analytics project! You've applied:\n",
    "\n",
    "- ‚úÖ Time series preprocessing techniques\n",
    "- ‚úÖ ARIMA forecasting\n",
    "- ‚úÖ Pattern recognition\n",
    "- ‚úÖ Business insights generation\n",
    "\n",
    "**These skills are directly applicable to:**\n",
    "- Sales forecasting\n",
    "- Demand planning\n",
    "- Resource optimization\n",
    "- Anomaly detection\n",
    "- Business intelligence\n",
    "\n",
    "**Great work! ‚òï‚ú®**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
