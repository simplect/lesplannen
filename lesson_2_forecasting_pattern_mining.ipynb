{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Time Series Forecasting & Pattern Mining\n",
    "\n",
    "## Learning Objectives\n",
    "- LO8: Make predictions using ARMA/ARIMA models\n",
    "- LO9: Recognize frequently occurring patterns (time series motifs)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import stumpy for motif detection (if not installed, we'll provide alternative)\n",
    "try:\n",
    "    import stumpy\n",
    "    STUMPY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    STUMPY_AVAILABLE = False\n",
    "    print(\"Note: stumpy not installed. Install with: pip install stumpy\")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Stumpy available: {STUMPY_AVAILABLE}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Opening Activity: \"Predict the Future\" (15 min)\n",
    "\n",
    "Let's start by visualizing some sales data and making intuitive predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate synthetic sales data with trend and seasonality\n",
    "np.random.seed(42)\n",
    "\n",
    "# 12 months of historical data\n",
    "months = pd.date_range('2023-01-01', periods=12, freq='MS')\n",
    "trend = np.linspace(100, 130, 12)\n",
    "seasonality = 20 * np.sin(2 * np.pi * np.arange(12) / 12)\n",
    "noise = np.random.normal(0, 5, 12)\n",
    "sales = trend + seasonality + noise\n",
    "\n",
    "# Create DataFrame\n",
    "df_sales = pd.DataFrame({\n",
    "    'month': months,\n",
    "    'sales': sales\n",
    "})\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_sales['month'], df_sales['sales'], marker='o', linewidth=2, markersize=10, color='steelblue')\n",
    "plt.axvline(x=df_sales['month'].iloc[-1], color='red', linestyle='--', linewidth=2, label='Today')\n",
    "plt.title('Sales Data - Past 12 Months', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Sales (units)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nü§î Activity:\")\n",
    "print(\"1. Draw or imagine the next 3 months of sales\")\n",
    "print(\"2. What patterns do you see in the historical data?\")\n",
    "print(\"3. What information are you using to make your prediction?\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí¨ Discussion with Your Neighbor\n",
    "\n",
    "**Share your predictions:**\n",
    "- What patterns did you identify? ___________\n",
    "- What will sales be in month 13? ___________\n",
    "- What assumptions did you make? ___________\n",
    "\n",
    "**Key insight:** You're using patterns from the past to predict the future - that's exactly what ARIMA does!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: ARMA & ARIMA Intuition (35 min)\n",
    "\n",
    "### Understanding the Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. AR (AutoRegressive) Model\n",
    "\n",
    "**Intuition:** \"Today's value depends on yesterday's and the day before\"\n",
    "\n",
    "**Formula:** X_t = c + œÜ‚ÇÅX_{t-1} + œÜ‚ÇÇX_{t-2} + ... + error\n",
    "\n",
    "**Example analogy:** Your mood today depends on your mood yesterday and the day before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Simulate AR processes with different parameters\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "\n",
    "def simulate_ar(phi, n=200):\n",
    "    \"\"\"Simulate AR(1) process: X_t = phi * X_{t-1} + error\"\"\"\n",
    "    x = np.zeros(n)\n",
    "    x[0] = np.random.normal()\n",
    "    for t in range(1, n):\n",
    "        x[t] = phi * x[t-1] + np.random.normal()\n",
    "    return x\n",
    "\n",
    "# Different AR processes\n",
    "ar_positive = simulate_ar(0.8)  # Strong positive correlation\n",
    "ar_moderate = simulate_ar(0.3)  # Moderate correlation\n",
    "ar_negative = simulate_ar(-0.5) # Negative correlation\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 10))\n",
    "\n",
    "axes[0].plot(ar_positive, linewidth=1)\n",
    "axes[0].set_title('AR(1) with œÜ = 0.8 (Strong positive correlation)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(ar_moderate, linewidth=1)\n",
    "axes[1].set_title('AR(1) with œÜ = 0.3 (Moderate correlation)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(ar_negative, linewidth=1, color='red')\n",
    "axes[2].set_title('AR(1) with œÜ = -0.5 (Negative correlation - oscillating)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Time')\n",
    "axes[2].set_ylabel('Value')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Observations:\")\n",
    "print(\"- œÜ > 0: Values tend to continue in the same direction (smooth trends)\")\n",
    "print(\"- œÜ close to 1: Very persistent, slow decay\")\n",
    "print(\"- œÜ < 0: Values oscillate (negative correlation)\")\n",
    "print(\"- œÜ close to 0: Like random noise\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Quick Poll\n",
    "\n",
    "Which of these time series would have strong AR behavior?\n",
    "\n",
    "1. Daily temperature: _____ (Yes/No)\n",
    "2. Rolling a die: _____ (Yes/No)\n",
    "3. Stock prices: _____ (Yes/No)\n",
    "4. Lottery numbers: _____ (Yes/No)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MA (Moving Average) Model\n",
    "\n",
    "**Intuition:** \"Today's value depends on recent shocks/surprises\"\n",
    "\n",
    "**Formula:** X_t = Œº + Œ∏‚ÇÅŒµ_{t-1} + Œ∏‚ÇÇŒµ_{t-2} + ... + Œµ_t\n",
    "\n",
    "**Example:** Your mood depends on recent unexpected events (surprises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def simulate_ma(theta, n=200):\n",
    "    \"\"\"Simulate MA(1) process: X_t = theta * error_{t-1} + error_t\"\"\"\n",
    "    errors = np.random.normal(0, 1, n)\n",
    "    x = np.zeros(n)\n",
    "    x[0] = errors[0]\n",
    "    for t in range(1, n):\n",
    "        x[t] = theta * errors[t-1] + errors[t]\n",
    "    return x\n",
    "\n",
    "# Different MA processes\n",
    "ma_positive = simulate_ma(0.8)\n",
    "ma_negative = simulate_ma(-0.8)\n",
    "\n",
    "# Visualize comparison of AR vs MA\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 8))\n",
    "\n",
    "axes[0, 0].plot(ar_positive, linewidth=1, color='blue')\n",
    "axes[0, 0].set_title('AR(1): œÜ = 0.8', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Value')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(ma_positive, linewidth=1, color='green')\n",
    "axes[0, 1].set_title('MA(1): Œ∏ = 0.8', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(ar_negative, linewidth=1, color='blue')\n",
    "axes[1, 0].set_title('AR(1): œÜ = -0.5', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Time')\n",
    "axes[1, 0].set_ylabel('Value')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(ma_negative, linewidth=1, color='green')\n",
    "axes[1, 1].set_title('MA(1): Œ∏ = -0.8', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Time')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Key Difference:\")\n",
    "print(\"- AR: Long memory - past values directly influence future\")\n",
    "print(\"- MA: Short memory - only recent shocks matter\")\n",
    "print(\"- AR processes look smoother and more persistent\")\n",
    "print(\"- MA processes look more 'choppy' with less persistence\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ARIMA: Putting It All Together\n",
    "\n",
    "**ARIMA(p, d, q)**\n",
    "- **p**: Number of AR (autoregressive) terms\n",
    "- **d**: Degree of differencing (for stationarity)\n",
    "- **q**: Number of MA (moving average) terms\n",
    "\n",
    "**The \"I\" (Integrated):** Differencing to make data stationary\n",
    "- d=0: No differencing (data already stationary)\n",
    "- d=1: First difference (X_t - X_{t-1})\n",
    "- d=2: Second difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Demonstrate differencing\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "\n",
    "# Non-stationary series (with trend)\n",
    "trend = 0.5 * np.arange(n)\n",
    "noise = np.random.normal(0, 5, n)\n",
    "non_stationary = trend + noise\n",
    "\n",
    "# First difference\n",
    "first_diff = np.diff(non_stationary)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "axes[0].plot(non_stationary, linewidth=1)\n",
    "axes[0].set_title('Original Series (Non-Stationary with Trend)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(first_diff, linewidth=1, color='orange')\n",
    "axes[1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_title('After First Differencing (Stationary)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('Differenced Value')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Differencing removes the trend and makes data stationary!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### üß™ Experiment 1: Play with AR Parameters (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# YOUR TURN: Experiment with different AR parameters\n",
    "phi_value = 0.9  # Try: 0.3, 0.5, 0.9, 0.99, -0.5, 1.1 (unstable!)\n",
    "\n",
    "# Simulate\n",
    "experiment_ar = simulate_ar(phi_value, n=300)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(experiment_ar, linewidth=1)\n",
    "plt.title(f'Your AR(1) Process with œÜ = {phi_value}', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Statistics for œÜ = {phi_value}:\")\n",
    "print(f\"Mean: {np.mean(experiment_ar):.2f}\")\n",
    "print(f\"Std Dev: {np.std(experiment_ar):.2f}\")\n",
    "print(f\"Min: {np.min(experiment_ar):.2f}\")\n",
    "print(f\"Max: {np.max(experiment_ar):.2f}\")\n",
    "\n",
    "print(\"\\nüí≠ Reflection Questions:\")\n",
    "print(\"- What happens when œÜ > 1? (Try it!)\")\n",
    "print(\"- What happens with negative œÜ?\")\n",
    "print(\"- Which œÜ value creates the smoothest series?\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### üß™ Experiment 2: Fit ARIMA on Real Data (10 min)\n",
    "\n",
    "Let's work through the complete ARIMA workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate realistic energy consumption data\n",
    "np.random.seed(42)\n",
    "days = pd.date_range('2023-01-01', periods=365, freq='D')\n",
    "trend = np.linspace(100, 110, 365)\n",
    "seasonal = 10 * np.sin(2 * np.pi * np.arange(365) / 7)  # Weekly seasonality\n",
    "noise = np.random.normal(0, 3, 365)\n",
    "energy = trend + seasonal + noise\n",
    "\n",
    "df_energy = pd.DataFrame({\n",
    "    'date': days,\n",
    "    'consumption': energy\n",
    "})\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df_energy['date'], df_energy['consumption'], linewidth=1)\n",
    "plt.title('Daily Energy Consumption', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy (kWh)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Dataset: {len(df_energy)} days of energy consumption data\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Check Stationarity (ADF Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def adf_test(series, name=''):\n",
    "    \"\"\"Perform Augmented Dickey-Fuller test for stationarity\"\"\"\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'\\nüìä ADF Test Results for {name}:')\n",
    "    print(f'ADF Statistic: {result[0]:.4f}')\n",
    "    print(f'p-value: {result[1]:.4f}')\n",
    "    print(f'Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'  {key}: {value:.3f}')\n",
    "    \n",
    "    if result[1] < 0.05:\n",
    "        print(\"\\n‚úÖ Result: Series is STATIONARY (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Result: Series is NON-STATIONARY (p >= 0.05) - needs differencing!\")\n",
    "    \n",
    "    return result[1] < 0.05\n",
    "\n",
    "# Test original series\n",
    "is_stationary = adf_test(df_energy['consumption'], 'Original Series')\n",
    "\n",
    "# If not stationary, try differencing\n",
    "if not is_stationary:\n",
    "    df_energy['consumption_diff'] = df_energy['consumption'].diff()\n",
    "    adf_test(df_energy['consumption_diff'], 'First Differenced Series')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Determine Parameters with ACF/PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot ACF and PACF\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Use differenced series if original wasn't stationary\n",
    "series_to_plot = df_energy['consumption_diff'].dropna() if not is_stationary else df_energy['consumption']\n",
    "\n",
    "plot_acf(series_to_plot, lags=30, ax=axes[0])\n",
    "axes[0].set_title('Autocorrelation Function (ACF)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plot_pacf(series_to_plot, lags=30, ax=axes[1])\n",
    "axes[1].set_title('Partial Autocorrelation Function (PACF)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìö How to read ACF/PACF:\")\n",
    "print(\"\\nPACF (for determining p):\")\n",
    "print(\"  - Significant spikes = number of AR terms (p)\")\n",
    "print(\"  - Look for where PACF cuts off\")\n",
    "print(\"\\nACF (for determining q):\")\n",
    "print(\"  - Significant spikes = number of MA terms (q)\")\n",
    "print(\"  - Look for where ACF cuts off\")\n",
    "print(\"\\nüí° Tip: Start with small values (1-3) and compare models!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Fit ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# YOUR TURN: Choose parameters based on ACF/PACF\n",
    "p = 1  # AR order (from PACF)\n",
    "d = 1  # Differencing order (1 if we needed differencing, 0 if not)\n",
    "q = 1  # MA order (from ACF)\n",
    "\n",
    "print(f\"\\nüîß Fitting ARIMA({p}, {d}, {q}) model...\")\n",
    "\n",
    "# Fit model\n",
    "model = ARIMA(df_energy['consumption'], order=(p, d, q))\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(fitted_model.summary())\n",
    "\n",
    "# Get fitted values\n",
    "df_energy['fitted'] = fitted_model.fittedvalues\n",
    "\n",
    "# Visualize fit\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_energy['date'], df_energy['consumption'], label='Actual', linewidth=1, alpha=0.7)\n",
    "plt.plot(df_energy['date'], df_energy['fitted'], label=f'ARIMA({p},{d},{q}) Fit', linewidth=2)\n",
    "plt.title('ARIMA Model Fit', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Consumption')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate error metrics\n",
    "residuals = df_energy['consumption'] - df_energy['fitted']\n",
    "mae = mean_absolute_error(df_energy['consumption'][d:], df_energy['fitted'][d:])\n",
    "rmse = np.sqrt(mean_squared_error(df_energy['consumption'][d:], df_energy['fitted'][d:]))\n",
    "\n",
    "print(f\"\\nüìä Model Performance:\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Make Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Forecast next 30 days\n",
    "forecast_steps = 30\n",
    "forecast = fitted_model.forecast(steps=forecast_steps)\n",
    "forecast_index = pd.date_range(start=df_energy['date'].iloc[-1] + pd.Timedelta(days=1), periods=forecast_steps, freq='D')\n",
    "\n",
    "# Get confidence intervals\n",
    "forecast_df = fitted_model.get_forecast(steps=forecast_steps)\n",
    "forecast_ci = forecast_df.conf_int()\n",
    "\n",
    "# Visualize forecast\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Historical data\n",
    "plt.plot(df_energy['date'], df_energy['consumption'], label='Historical', linewidth=2, color='steelblue')\n",
    "\n",
    "# Forecast\n",
    "plt.plot(forecast_index, forecast, label='Forecast', linewidth=2, color='red', linestyle='--')\n",
    "\n",
    "# Confidence intervals\n",
    "plt.fill_between(forecast_index, \n",
    "                 forecast_ci.iloc[:, 0], \n",
    "                 forecast_ci.iloc[:, 1], \n",
    "                 alpha=0.3, \n",
    "                 color='red',\n",
    "                 label='95% Confidence Interval')\n",
    "\n",
    "plt.axvline(x=df_energy['date'].iloc[-1], color='black', linestyle=':', linewidth=2, label='Forecast Start')\n",
    "plt.title(f'ARIMA({p},{d},{q}) Forecast - Next {forecast_steps} Days', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Consumption')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüîÆ Forecast for next {forecast_steps} days:\")\n",
    "forecast_summary = pd.DataFrame({\n",
    "    'Date': forecast_index,\n",
    "    'Forecast': forecast.values,\n",
    "    'Lower CI': forecast_ci.iloc[:, 0].values,\n",
    "    'Upper CI': forecast_ci.iloc[:, 1].values\n",
    "})\n",
    "print(forecast_summary.head(10))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí≠ Reflection Questions:\n",
    "\n",
    "1. Why might your ARIMA parameters differ from your neighbor's? ___________\n",
    "\n",
    "2. What does the PACF plot tell you about the data? ___________\n",
    "\n",
    "3. How confident are you in the forecast for day 1 vs day 30? Why? ___________\n",
    "\n",
    "4. Try different (p,d,q) values - which combination gives the lowest MAE? ___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚òï BREAK (10 minutes)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Time Series Forecasting in Practice (25 min)\n",
    "\n",
    "### Case-Based Learning\n",
    "\n",
    "Work in groups of 3. Each group will receive ONE scenario below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario Selection\n",
    "\n",
    "**Choose your scenario:**\n",
    "\n",
    "1. **Retail**: Predict demand for sunscreen next summer\n",
    "2. **Energy**: Predict electricity consumption for the coming week\n",
    "3. **Maintenance**: Predict when machine maintenance is needed\n",
    "4. **Finance**: Predict revenue for the next quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate different datasets for each scenario\n",
    "np.random.seed(42)\n",
    "\n",
    "def create_scenario_data(scenario_type):\n",
    "    \"\"\"Create realistic data for different scenarios\"\"\"\n",
    "    \n",
    "    if scenario_type == 'retail':\n",
    "        # Sunscreen sales - strong yearly seasonality\n",
    "        days = pd.date_range('2021-01-01', periods=1095, freq='D')  # 3 years\n",
    "        trend = np.linspace(100, 150, 1095)\n",
    "        yearly_season = 80 * np.sin(2 * np.pi * np.arange(1095) / 365 - np.pi/2)  # Peak in summer\n",
    "        noise = np.random.normal(0, 10, 1095)\n",
    "        values = trend + yearly_season + noise\n",
    "        values = np.maximum(values, 5)  # No negative sales\n",
    "        label = 'Sunscreen Sales (units)'\n",
    "        \n",
    "    elif scenario_type == 'energy':\n",
    "        # Electricity consumption - weekly + daily patterns\n",
    "        hours = pd.date_range('2023-01-01', periods=24*90, freq='H')  # 90 days hourly\n",
    "        days = hours\n",
    "        trend = np.linspace(500, 520, len(hours))\n",
    "        daily_season = 100 * np.sin(2 * np.pi * np.arange(len(hours)) / 24)\n",
    "        weekly_season = 50 * np.sin(2 * np.pi * np.arange(len(hours)) / (24*7))\n",
    "        noise = np.random.normal(0, 20, len(hours))\n",
    "        values = trend + daily_season + weekly_season + noise\n",
    "        label = 'Electricity Consumption (kWh)'\n",
    "        \n",
    "    elif scenario_type == 'maintenance':\n",
    "        # Machine vibration - increasing trend before failure\n",
    "        hours = pd.date_range('2023-01-01', periods=24*60, freq='H')  # 60 days hourly\n",
    "        days = hours\n",
    "        trend = 0.01 * np.arange(len(hours))  # Gradual increase\n",
    "        noise = np.random.normal(0, 2, len(hours))\n",
    "        # Add sudden spikes (anomalies)\n",
    "        spikes = np.zeros(len(hours))\n",
    "        spike_indices = np.random.choice(len(hours), size=10, replace=False)\n",
    "        spikes[spike_indices] = np.random.uniform(10, 20, 10)\n",
    "        values = 50 + trend + noise + spikes\n",
    "        label = 'Machine Vibration (mm/s)'\n",
    "        \n",
    "    else:  # finance\n",
    "        # Revenue - quarterly seasonality with trend\n",
    "        months = pd.date_range('2020-01-01', periods=48, freq='MS')  # 4 years monthly\n",
    "        days = months\n",
    "        trend = np.linspace(1000, 1500, 48)\n",
    "        quarterly_season = 200 * np.sin(2 * np.pi * np.arange(48) / 12)\n",
    "        noise = np.random.normal(0, 50, 48)\n",
    "        values = trend + quarterly_season + noise\n",
    "        label = 'Monthly Revenue ($1000s)'\n",
    "    \n",
    "    return pd.DataFrame({'date': days, 'value': values}), label\n",
    "\n",
    "# SELECT YOUR SCENARIO HERE\n",
    "scenario = 'retail'  # Change to: 'retail', 'energy', 'maintenance', or 'finance'\n",
    "\n",
    "df_scenario, value_label = create_scenario_data(scenario)\n",
    "\n",
    "# Visualize scenario data\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_scenario['date'], df_scenario['value'], linewidth=1)\n",
    "plt.title(f'Scenario: {scenario.upper()} - Historical Data', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(value_label)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìã Your scenario: {scenario.upper()}\")\n",
    "print(f\"Dataset size: {len(df_scenario)} observations\")\n",
    "print(f\"Date range: {df_scenario['date'].min()} to {df_scenario['date'].max()}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Group Task (15 minutes)\n",
    "\n",
    "Complete the following steps with your group:\n",
    "\n",
    "1. **Analyze** the historical data\n",
    "2. **Determine** ARIMA parameters (p, d, q)\n",
    "3. **Fit** the model\n",
    "4. **Make** forecasts with confidence intervals\n",
    "5. **Evaluate** performance (MAE, RMSE)\n",
    "\n",
    "Use the code cell below for your analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# GROUP WORK SPACE\n",
    "\n",
    "# Step 1: Check stationarity\n",
    "print(\"=\" * 50)\n",
    "print(\"STEP 1: STATIONARITY CHECK\")\n",
    "print(\"=\" * 50)\n",
    "is_stationary = adf_test(df_scenario['value'], 'Scenario Data')\n",
    "\n",
    "# Step 2: ACF/PACF plots\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 2: ACF/PACF ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "series_for_plots = df_scenario['value'].diff().dropna() if not is_stationary else df_scenario['value']\n",
    "plot_acf(series_for_plots, lags=40, ax=axes[0])\n",
    "axes[0].set_title('ACF')\n",
    "plot_pacf(series_for_plots, lags=40, ax=axes[1])\n",
    "axes[1].set_title('PACF')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Choose your parameters\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 3: CHOOSE PARAMETERS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# YOUR PARAMETERS HERE (discuss with your group)\n",
    "p = 1  # AR order\n",
    "d = 1  # Differencing\n",
    "q = 1  # MA order\n",
    "\n",
    "print(f\"\\nChosen parameters: ARIMA({p}, {d}, {q})\")\n",
    "\n",
    "# Step 4: Fit model\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 4: FIT MODEL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "model = ARIMA(df_scenario['value'], order=(p, d, q))\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# Step 5: Make forecast\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 5: FORECAST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "forecast_steps = 30  # Adjust based on your scenario\n",
    "forecast = fitted_model.forecast(steps=forecast_steps)\n",
    "forecast_obj = fitted_model.get_forecast(steps=forecast_steps)\n",
    "forecast_ci = forecast_obj.conf_int()\n",
    "\n",
    "# Determine forecast index frequency based on original data\n",
    "freq = pd.infer_freq(df_scenario['date'])\n",
    "if freq is None:\n",
    "    freq = 'D'  # Default to daily\n",
    "\n",
    "forecast_index = pd.date_range(start=df_scenario['date'].iloc[-1] + pd.Timedelta(days=1), \n",
    "                               periods=forecast_steps, freq=freq)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_scenario['date'], df_scenario['value'], label='Historical', linewidth=2)\n",
    "plt.plot(forecast_index, forecast, label='Forecast', linewidth=2, color='red', linestyle='--')\n",
    "plt.fill_between(forecast_index, forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1], \n",
    "                 alpha=0.3, color='red', label='95% CI')\n",
    "plt.axvline(x=df_scenario['date'].iloc[-1], color='black', linestyle=':', linewidth=2)\n",
    "plt.title(f'Forecast: {scenario.upper()}', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(value_label)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Evaluate\n",
    "fitted_values = fitted_model.fittedvalues\n",
    "mae = mean_absolute_error(df_scenario['value'][d:], fitted_values[d:])\n",
    "rmse = np.sqrt(mean_squared_error(df_scenario['value'][d:], fitted_values[d:]))\n",
    "\n",
    "print(f\"\\nüìä MODEL PERFORMANCE:\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"AIC: {fitted_model.aic:.2f}\")\n",
    "print(f\"BIC: {fitted_model.bic:.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Prepare Your Findings for Gallery Walk\n",
    "\n",
    "**Key findings to share:**\n",
    "\n",
    "1. **Scenario:** ___________\n",
    "2. **ARIMA Parameters:** (p, d, q) = ___________\n",
    "3. **Reasoning:** Why did you choose these parameters? ___________\n",
    "4. **Forecast:** What is your prediction? ___________\n",
    "5. **Confidence:** How certain are you? (Look at CI width) ___________\n",
    "6. **Challenges:** What was difficult? ___________\n",
    "7. **MAE/RMSE:** ___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üö∂ Gallery Walk (10 minutes)\n",
    "\n",
    "- Display your results\n",
    "- Walk around and view other groups' work\n",
    "- Place feedback/questions on post-its\n",
    "- Discuss: Why do forecasts differ between groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Time Series Motifs (Pattern Mining) (30 min)\n",
    "\n",
    "### Motivation\n",
    "\n",
    "**\"Forecasting is important, but sometimes we want to recognize recurring patterns\"**\n",
    "\n",
    "**Applications:**\n",
    "- ECG: Recognize heartbeat patterns\n",
    "- Website traffic: Detect user behavior patterns\n",
    "- Manufacturing: Predict quality issues from recurring patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are Motifs?\n",
    "\n",
    "**Motifs** = Subsequences that occur frequently in a time series\n",
    "\n",
    "**Applications:**\n",
    "- Anomaly detection (find patterns that DON'T match)\n",
    "- Clustering similar time windows\n",
    "- Classification based on pattern presence\n",
    "\n",
    "**Techniques:**\n",
    "- Matrix Profile\n",
    "- Symbolic representation (SAX)\n",
    "- Distance-based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate machine sensor data with repeating patterns\n",
    "np.random.seed(42)\n",
    "\n",
    "def create_pattern(length=50):\n",
    "    \"\"\"Create a distinct pattern\"\"\"\n",
    "    return 10 * np.sin(2 * np.pi * np.arange(length) / 10) + np.random.normal(0, 1, length)\n",
    "\n",
    "# Create synthetic sensor data\n",
    "n_points = 1000\n",
    "sensor_data = np.random.normal(50, 3, n_points)\n",
    "\n",
    "# Pattern 1: Normal operation (appears multiple times)\n",
    "pattern_normal = create_pattern(50)\n",
    "positions_normal = [100, 300, 500, 700]\n",
    "for pos in positions_normal:\n",
    "    sensor_data[pos:pos+50] = 50 + pattern_normal\n",
    "\n",
    "# Pattern 2: Start/stop phase\n",
    "pattern_startstop = 5 * np.exp(-np.arange(50)/10) * np.sin(np.arange(50)/2)\n",
    "positions_startstop = [200, 600]\n",
    "for pos in positions_startstop:\n",
    "    sensor_data[pos:pos+50] = 50 + pattern_startstop\n",
    "\n",
    "# Pattern 3: Potential issue (spike pattern)\n",
    "pattern_issue = np.zeros(50)\n",
    "pattern_issue[20:30] = 15\n",
    "positions_issue = [400, 800]\n",
    "for pos in positions_issue:\n",
    "    sensor_data[pos:pos+50] = 50 + pattern_issue + np.random.normal(0, 2, 50)\n",
    "\n",
    "# Create DataFrame\n",
    "time = pd.date_range('2023-01-01', periods=n_points, freq='T')\n",
    "df_sensor = pd.DataFrame({\n",
    "    'time': time,\n",
    "    'value': sensor_data\n",
    "})\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_sensor['time'], df_sensor['value'], linewidth=0.5, alpha=0.8)\n",
    "\n",
    "# Highlight pattern locations\n",
    "for pos in positions_normal:\n",
    "    plt.axvspan(time[pos], time[pos+49], alpha=0.2, color='green', label='Normal' if pos == positions_normal[0] else '')\n",
    "for pos in positions_startstop:\n",
    "    plt.axvspan(time[pos], time[pos+49], alpha=0.2, color='blue', label='Start/Stop' if pos == positions_startstop[0] else '')\n",
    "for pos in positions_issue:\n",
    "    plt.axvspan(time[pos], time[pos+49], alpha=0.2, color='red', label='Issue' if pos == positions_issue[0] else '')\n",
    "\n",
    "plt.title('Machine Sensor Readings (with hidden patterns)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sensor Value')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Goal: Find the top-3 most common patterns (motifs) in this data!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif Detection with Matrix Profile\n",
    "\n",
    "We'll use the **stumpy** library for efficient motif detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if STUMPY_AVAILABLE:\n",
    "    # Compute matrix profile\n",
    "    window_size = 50  # Size of patterns to look for\n",
    "    matrix_profile = stumpy.stump(df_sensor['value'], m=window_size)\n",
    "    \n",
    "    # Find top-3 motifs\n",
    "    motifs = stumpy.motifs(df_sensor['value'], matrix_profile[:, 0], max_motifs=3, max_matches=10)\n",
    "    \n",
    "    # Visualize motifs\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Original data\n",
    "    axes[0].plot(df_sensor['value'], linewidth=0.5, alpha=0.7)\n",
    "    axes[0].set_title('Original Sensor Data', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Value')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot each motif\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    for i in range(min(3, len(motifs))):\n",
    "        motif_indices = motifs[i]\n",
    "        \n",
    "        # Highlight motif locations in original data\n",
    "        for idx in motif_indices:\n",
    "            axes[0].axvspan(idx, idx + window_size, alpha=0.2, color=colors[i])\n",
    "        \n",
    "        # Plot motif instances\n",
    "        for j, idx in enumerate(motif_indices):\n",
    "            axes[i+1].plot(df_sensor['value'].iloc[idx:idx+window_size].values, \n",
    "                          alpha=0.7, label=f'Instance {j+1} (pos {idx})')\n",
    "        \n",
    "        axes[i+1].set_title(f'Motif {i+1}: Found {len(motif_indices)} instances', \n",
    "                           fontsize=12, fontweight='bold', color=colors[i])\n",
    "        axes[i+1].set_ylabel('Value')\n",
    "        axes[i+1].legend(loc='upper right')\n",
    "        axes[i+1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüîç Motif Detection Results:\")\n",
    "    for i, motif_indices in enumerate(motifs[:3]):\n",
    "        print(f\"\\nMotif {i+1}:\")\n",
    "        print(f\"  - Found {len(motif_indices)} instances\")\n",
    "        print(f\"  - Locations: {motif_indices}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Stumpy not available. Using alternative simple pattern detection...\")\n",
    "    print(\"\\nInstall stumpy with: pip install stumpy\")\n",
    "    print(\"\\nAlternatively, we'll use a simple sliding window correlation approach:\")\n",
    "    \n",
    "    # Simple pattern detection using correlation\n",
    "    window_size = 50\n",
    "    correlations = []\n",
    "    \n",
    "    # Take first window as template\n",
    "    template = df_sensor['value'].iloc[100:150].values\n",
    "    \n",
    "    # Find similar patterns\n",
    "    similar_positions = []\n",
    "    threshold = 0.8\n",
    "    \n",
    "    for i in range(len(df_sensor) - window_size):\n",
    "        window = df_sensor['value'].iloc[i:i+window_size].values\n",
    "        corr = np.corrcoef(template, window)[0, 1]\n",
    "        if corr > threshold and i > 50:  # Avoid overlapping with template\n",
    "            similar_positions.append(i)\n",
    "    \n",
    "    print(f\"\\nüîç Found {len(similar_positions)} similar patterns to template at position 100\")\n",
    "    print(f\"Locations: {similar_positions[:5]}...\")  # Show first 5"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Exercise: Link Motifs to Events\n",
    "\n",
    "Look at the motifs discovered above and answer:\n",
    "\n",
    "**Motif 1:**\n",
    "- Pattern shape: ___________\n",
    "- Likely represents: ‚òê Normal operation ‚òê Start/Stop ‚òê Issue\n",
    "- Reasoning: ___________\n",
    "\n",
    "**Motif 2:**\n",
    "- Pattern shape: ___________\n",
    "- Likely represents: ‚òê Normal operation ‚òê Start/Stop ‚òê Issue\n",
    "- Reasoning: ___________\n",
    "\n",
    "**Motif 3:**\n",
    "- Pattern shape: ___________\n",
    "- Likely represents: ‚òê Normal operation ‚òê Start/Stop ‚òê Issue\n",
    "- Reasoning: ___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Reflection: Predictive Maintenance Application\n",
    "\n",
    "**How could you use motif detection for predictive maintenance?**\n",
    "\n",
    "Ideas:\n",
    "1. ___________________________________________\n",
    "2. ___________________________________________\n",
    "3. ___________________________________________\n",
    "\n",
    "**Discussion prompt:** What pattern would indicate an upcoming failure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üë• Peer Discussion (5 minutes)\n",
    "\n",
    "Compare with your neighbor:\n",
    "\n",
    "1. **Which motifs did you each find?**\n",
    "2. **Do you agree on the interpretation?**\n",
    "3. **What's the most interesting insight?**\n",
    "\n",
    "Be ready to share with the class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Integration & Reflection (5 min)\n",
    "\n",
    "### Group Discussion: When to use ARIMA vs Motif Analysis?\n",
    "\n",
    "| Technique | Best Used For | Example |\n",
    "|-----------|--------------|----------|\n",
    "| **ARIMA** | Forecasting future values | Predicting next month's sales |\n",
    "| **Motif Analysis** | Pattern recognition, anomaly detection | Finding normal vs abnormal machine behavior |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Final Reflection\n",
    "\n",
    "**Post your answers (individually):**\n",
    "\n",
    "1. **What is the difference between forecasting and pattern recognition?**\n",
    "\n",
    "   ___________________________________________\n",
    "\n",
    "2. **Name ONE practical application from today that you find interesting:**\n",
    "\n",
    "   ___________________________________________\n",
    "\n",
    "3. **What do you want to learn more about regarding time series?**\n",
    "\n",
    "   ___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "### ARIMA Forecasting:\n",
    "1. **AR (p)**: Past values influence future (autoregressive)\n",
    "2. **I (d)**: Differencing for stationarity\n",
    "3. **MA (q)**: Past errors influence future (moving average)\n",
    "4. **Process**: Check stationarity ‚Üí ACF/PACF ‚Üí Fit ‚Üí Forecast ‚Üí Evaluate\n",
    "5. **Always include confidence intervals!**\n",
    "\n",
    "### Pattern Mining:\n",
    "1. **Motifs**: Frequently occurring subsequences\n",
    "2. **Applications**: Anomaly detection, clustering, classification\n",
    "3. **Matrix Profile**: Efficient method for motif discovery\n",
    "4. **Practical use**: Recognize normal patterns to detect abnormal ones\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "**Further learning:**\n",
    "- SARIMA for seasonal patterns\n",
    "- Prophet for trend+seasonality\n",
    "- Deep learning (LSTM) for complex time series\n",
    "\n",
    "**Additional resources:**\n",
    "- [Statsmodels documentation](https://www.statsmodels.org/)\n",
    "- [Stumpy Matrix Profile](https://stumpy.readthedocs.io/)\n",
    "- Time series papers and tutorials\n",
    "\n",
    "---\n",
    "\n",
    "## Thank you! üëã\n",
    "\n",
    "**Great work today on forecasting and pattern mining!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
